{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Aug 19 10:30:37 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.54.03              Driver Version: 535.54.03    CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Quadro RTX 6000                On  | 00000000:01:00.0 Off |                  Off |\n",
      "| 46%   68C    P2             262W / 260W |  20529MiB / 24576MiB |    100%   E. Process |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  Quadro RTX 6000                On  | 00000000:25:00.0 Off |                  Off |\n",
      "| 47%   70C    P2             224W / 260W |   1451MiB / 24576MiB |     91%   E. Process |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  Quadro RTX 6000                On  | 00000000:41:00.0 Off |                  Off |\n",
      "| 33%   30C    P8               7W / 260W |      1MiB / 24576MiB |      0%   E. Process |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  Quadro RTX 6000                On  | 00000000:61:00.0 Off |                  Off |\n",
      "| 33%   40C    P2              75W / 260W |   1355MiB / 24576MiB |     17%   E. Process |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   4  Quadro RTX 6000                On  | 00000000:81:00.0 Off |                  Off |\n",
      "| 46%   69C    P2             261W / 260W |  16377MiB / 24576MiB |     92%   E. Process |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   5  Quadro RTX 6000                On  | 00000000:A1:00.0 Off |                  Off |\n",
      "| 34%   61C    P2             175W / 260W |   5069MiB / 24576MiB |     95%   E. Process |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   6  Quadro RTX 6000                On  | 00000000:C1:00.0 Off |                  Off |\n",
      "| 33%   49C    P2              91W / 260W |  23175MiB / 24576MiB |     76%   E. Process |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   7  Quadro RTX 6000                On  | 00000000:E1:00.0 Off |                  Off |\n",
      "| 33%   60C    P2             168W / 260W |   6013MiB / 24576MiB |     49%   E. Process |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A   2759624      C   python                                    20526MiB |\n",
      "|    1   N/A  N/A    277652      C   python                                     1448MiB |\n",
      "|    3   N/A  N/A    606784      C   python                                     1352MiB |\n",
      "|    4   N/A  N/A    338382      C   python                                    16374MiB |\n",
      "|    5   N/A  N/A   1570800      C   python                                     5066MiB |\n",
      "|    6   N/A  N/A   1569501      C   ...me/anaconda3/envs/tf-gpu/bin/python    23172MiB |\n",
      "|    7   N/A  N/A    464274      C   python                                     6010MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.4.0-cp312-cp312-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading filelock-3.15.4-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Collecting sympy (from torch)\n",
      "  Downloading sympy-1.13.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Downloading jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: setuptools in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from torch) (71.0.4)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
      "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.0.0 (from torch)\n",
      "  Downloading triton-3.0.0-1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Downloading MarkupSafe-2.1.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading torch-2.4.0-cp312-cp312-manylinux1_x86_64.whl (797.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.2/797.2 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.0.0-1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.15.4-py3-none-any.whl (16 kB)\n",
      "Downloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.3/133.3 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.13.2-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading MarkupSafe-2.1.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, MarkupSafe, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch\n",
      "Successfully installed MarkupSafe-2.1.5 filelock-3.15.4 fsspec-2024.6.1 jinja2-3.1.4 mpmath-1.3.0 networkx-3.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 sympy-1.13.2 torch-2.4.0 triton-3.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting torch_geometric\n",
      "  Downloading torch_geometric-2.5.3-py3-none-any.whl.metadata (64 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tqdm (from torch_geometric)\n",
      "  Downloading tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from torch_geometric) (2.0.1)\n",
      "Collecting scipy (from torch_geometric)\n",
      "  Downloading scipy-1.14.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from torch_geometric) (2024.6.1)\n",
      "Requirement already satisfied: jinja2 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from torch_geometric) (3.1.4)\n",
      "Collecting aiohttp (from torch_geometric)\n",
      "  Downloading aiohttp-3.10.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
      "Collecting requests (from torch_geometric)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: pyparsing in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from torch_geometric) (3.1.2)\n",
      "Collecting scikit-learn (from torch_geometric)\n",
      "  Downloading scikit_learn-1.5.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: psutil>=5.8.0 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from torch_geometric) (6.0.0)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->torch_geometric)\n",
      "  Downloading aiohappyeyeballs-2.3.5-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->torch_geometric)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->torch_geometric)\n",
      "  Downloading attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->torch_geometric)\n",
      "  Downloading frozenlist-1.4.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->torch_geometric)\n",
      "  Downloading multidict-6.0.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->torch_geometric)\n",
      "  Downloading yarl-1.9.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from jinja2->torch_geometric) (2.1.5)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->torch_geometric)\n",
      "  Downloading charset_normalizer-3.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->torch_geometric)\n",
      "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->torch_geometric)\n",
      "  Downloading urllib3-2.2.2-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->torch_geometric)\n",
      "  Downloading certifi-2024.7.4-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->torch_geometric)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->torch_geometric)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.10.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.5.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m122.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.14.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (40.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m143.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohappyeyeballs-2.3.5-py3-none-any.whl (12 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading certifi-2024.7.4-py3-none-any.whl (162 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.0/163.0 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading charset_normalizer-3.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading frozenlist-1.4.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (281 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.5/281.5 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.0.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.8/130.8 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Downloading urllib3-2.2.2-py3-none-any.whl (121 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.4/121.4 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.9.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (322 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.4/322.4 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: urllib3, tqdm, threadpoolctl, scipy, multidict, joblib, idna, frozenlist, charset-normalizer, certifi, attrs, aiohappyeyeballs, yarl, scikit-learn, requests, aiosignal, aiohttp, torch_geometric\n",
      "Successfully installed aiohappyeyeballs-2.3.5 aiohttp-3.10.3 aiosignal-1.3.1 attrs-24.2.0 certifi-2024.7.4 charset-normalizer-3.3.2 frozenlist-1.4.1 idna-3.7 joblib-1.4.2 multidict-6.0.5 requests-2.32.3 scikit-learn-1.5.1 scipy-1.14.0 threadpoolctl-3.5.0 torch_geometric-2.5.3 tqdm-4.66.5 urllib3-2.2.2 yarl-1.9.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting lightning\n",
      "  Downloading lightning-2.4.0-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting PyYAML<8.0,>=5.4 (from lightning)\n",
      "  Downloading PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: fsspec<2026.0,>=2022.5.0 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (2024.6.1)\n",
      "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning)\n",
      "  Downloading lightning_utilities-0.11.6-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: packaging<25.0,>=20.0 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from lightning) (24.1)\n",
      "Requirement already satisfied: torch<4.0,>=2.1.0 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from lightning) (2.4.0)\n",
      "Collecting torchmetrics<3.0,>=0.7.0 (from lightning)\n",
      "  Downloading torchmetrics-1.4.1-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: tqdm<6.0,>=4.57.0 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from lightning) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from lightning) (4.12.2)\n",
      "Collecting pytorch-lightning (from lightning)\n",
      "  Downloading pytorch_lightning-2.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (3.10.3)\n",
      "Requirement already satisfied: setuptools in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from lightning-utilities<2.0,>=0.10.0->lightning) (71.0.4)\n",
      "Requirement already satisfied: filelock in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from torch<4.0,>=2.1.0->lightning) (3.15.4)\n",
      "Requirement already satisfied: sympy in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from torch<4.0,>=2.1.0->lightning) (1.13.2)\n",
      "Requirement already satisfied: networkx in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from torch<4.0,>=2.1.0->lightning) (3.3)\n",
      "Requirement already satisfied: jinja2 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from torch<4.0,>=2.1.0->lightning) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from torch<4.0,>=2.1.0->lightning) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from torch<4.0,>=2.1.0->lightning) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from torch<4.0,>=2.1.0->lightning) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from torch<4.0,>=2.1.0->lightning) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from torch<4.0,>=2.1.0->lightning) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from torch<4.0,>=2.1.0->lightning) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from torch<4.0,>=2.1.0->lightning) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from torch<4.0,>=2.1.0->lightning) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from torch<4.0,>=2.1.0->lightning) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from torch<4.0,>=2.1.0->lightning) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from torch<4.0,>=2.1.0->lightning) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from torch<4.0,>=2.1.0->lightning) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<4.0,>=2.1.0->lightning) (12.6.20)\n",
      "Requirement already satisfied: numpy>1.20.0 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from torchmetrics<3.0,>=0.7.0->lightning) (2.0.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (2.3.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.9.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from jinja2->torch<4.0,>=2.1.0->lightning) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from sympy->torch<4.0,>=2.1.0->lightning) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.0 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (3.7)\n",
      "Downloading lightning-2.4.0-py3-none-any.whl (810 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m811.0/811.0 kB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lightning_utilities-0.11.6-py3-none-any.whl (26 kB)\n",
      "Downloading PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (767 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m767.5/767.5 kB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchmetrics-1.4.1-py3-none-any.whl (866 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m866.2/866.2 kB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytorch_lightning-2.4.0-py3-none-any.whl (815 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: PyYAML, lightning-utilities, torchmetrics, pytorch-lightning, lightning\n",
      "Successfully installed PyYAML-6.0.2 lightning-2.4.0 lightning-utilities-0.11.6 pytorch-lightning-2.4.0 torchmetrics-1.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting wandb\n",
      "  Downloading wandb-0.17.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting click!=8.0.0,>=7.1 (from wandb)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n",
      "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: platformdirs in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from wandb) (4.2.2)\n",
      "Collecting protobuf!=4.21.0,<6,>=3.19.0 (from wandb)\n",
      "  Downloading protobuf-5.27.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: psutil>=5.0.0 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from wandb) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from wandb) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from wandb) (2.32.3)\n",
      "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
      "  Downloading sentry_sdk-2.13.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting setproctitle (from wandb)\n",
      "  Downloading setproctitle-1.3.3-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: setuptools in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from wandb) (71.0.4)\n",
      "Requirement already satisfied: six>=1.4.0 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (2024.7.4)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Downloading wandb-0.17.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m138.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-5.27.3-cp38-abi3-manylinux2014_x86_64.whl (309 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.3/309.3 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sentry_sdk-2.13.0-py2.py3-none-any.whl (309 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.1/309.1 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading setproctitle-1.3.3-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
      "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: smmap, setproctitle, sentry-sdk, protobuf, docker-pycreds, click, gitdb, gitpython, wandb\n",
      "Successfully installed click-8.1.7 docker-pycreds-0.4.0 gitdb-4.0.11 gitpython-3.1.43 protobuf-5.27.3 sentry-sdk-2.13.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.17.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting scikit-image\n",
      "  Downloading scikit_image-0.24.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from scikit-image) (2.0.1)\n",
      "Requirement already satisfied: scipy>=1.9 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from scikit-image) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.8 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from scikit-image) (3.3)\n",
      "Requirement already satisfied: pillow>=9.1 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from scikit-image) (10.4.0)\n",
      "Collecting imageio>=2.33 (from scikit-image)\n",
      "  Downloading imageio-2.35.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image)\n",
      "  Downloading tifffile-2024.8.10-py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: packaging>=21 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from scikit-image) (24.1)\n",
      "Collecting lazy-loader>=0.4 (from scikit-image)\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting numpy>=1.23 (from scikit-image)\n",
      "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_image-0.24.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.0/15.0 MB\u001b[0m \u001b[31m164.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading imageio-2.35.0-py3-none-any.whl (315 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.4/315.4 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m164.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tifffile-2024.8.10-py3-none-any.whl (225 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.8/225.8 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy, lazy-loader, tifffile, imageio, scikit-image\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.1\n",
      "    Uninstalling numpy-2.0.1:\n",
      "      Successfully uninstalled numpy-2.0.1\n",
      "Successfully installed imageio-2.35.0 lazy-loader-0.4 numpy-1.26.4 scikit-image-0.24.0 tifffile-2024.8.10\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting egnn-pytorch\n",
      "  Downloading egnn_pytorch-0.2.7-py3-none-any.whl.metadata (748 bytes)\n",
      "Collecting einops>=0.3 (from egnn-pytorch)\n",
      "  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting numba (from egnn-pytorch)\n",
      "  Downloading numba-0.60.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: numpy in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from egnn-pytorch) (1.26.4)\n",
      "Requirement already satisfied: torch>=1.6 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from egnn-pytorch) (2.4.0)\n",
      "Requirement already satisfied: filelock in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from torch>=1.6->egnn-pytorch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from torch>=1.6->egnn-pytorch) (4.12.2)\n",
      "Requirement already satisfied: sympy in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from torch>=1.6->egnn-pytorch) (1.13.2)\n",
      "Requirement already satisfied: networkx in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from torch>=1.6->egnn-pytorch) (3.3)\n",
      "Requirement already satisfied: jinja2 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from torch>=1.6->egnn-pytorch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from torch>=1.6->egnn-pytorch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from torch>=1.6->egnn-pytorch) (71.0.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from torch>=1.6->egnn-pytorch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from torch>=1.6->egnn-pytorch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from torch>=1.6->egnn-pytorch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from torch>=1.6->egnn-pytorch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from torch>=1.6->egnn-pytorch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from torch>=1.6->egnn-pytorch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from torch>=1.6->egnn-pytorch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from torch>=1.6->egnn-pytorch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from torch>=1.6->egnn-pytorch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from torch>=1.6->egnn-pytorch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from torch>=1.6->egnn-pytorch) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from torch>=1.6->egnn-pytorch) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6->egnn-pytorch) (12.6.20)\n",
      "Collecting llvmlite<0.44,>=0.43.0dev0 (from numba->egnn-pytorch)\n",
      "  Downloading llvmlite-0.43.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from jinja2->torch>=1.6->egnn-pytorch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from sympy->torch>=1.6->egnn-pytorch) (1.3.0)\n",
      "Downloading egnn_pytorch-0.2.7-py3-none-any.whl (12 kB)\n",
      "Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numba-0.60.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m91.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.43.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 MB\u001b[0m \u001b[31m126.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: llvmlite, einops, numba, egnn-pytorch\n",
      "Successfully installed egnn-pytorch-0.2.7 einops-0.8.0 llvmlite-0.43.0 numba-0.60.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.23 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from matplotlib) (2.9.0)\n",
      "Requirement already satisfied: six>=1.5 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: seaborn in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from seaborn) (2.2.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from seaborn) (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in ./anaconda3/envs/torch_cuda_env/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision\n",
    "%pip install torch_geometric\n",
    "%pip install lightning\n",
    "%pip install wandb\n",
    "%pip install scikit-image\n",
    "%pip install egnn-pytorch\n",
    "%pip install matplotlib\n",
    "%pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/pbs.9924207.pbs/ipykernel_1575621/2284059768.py:13: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  set_matplotlib_formats('svg', 'pdf') # For export\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "## Standard libraries\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg', 'pdf') # For export\n",
    "from matplotlib.colors import to_rgb\n",
    "import matplotlib\n",
    "from mpl_toolkits.mplot3d.axes3d import Axes3D\n",
    "from mpl_toolkits.mplot3d import proj3d\n",
    "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
    "import seaborn as sns\n",
    "sns.reset_orig()\n",
    "\n",
    "## PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data_utils\n",
    "import torch.optim as optim\n",
    "# Torchvision\n",
    "import torchvision\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import transforms\n",
    "# Metrics\n",
    "import wandb\n",
    "# PyTorch Lightning\n",
    "import lightning as pl\n",
    "from lightning.pytorch.trainer import Trainer\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from lightning.pytorch.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "\n",
    "# Path to the folder where the datasets are/should be downloaded (e.g. CIFAR10)\n",
    "DATASET_PATH = \"./data\"\n",
    "# Path to the folder where the pretrained models are saved\n",
    "CHECKPOINT_PATH = \"./saved_models/ebm\"\n",
    "\n",
    "# Setting the seed\n",
    "pl.seed_everything(42)\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwc5118\u001b[0m (\u001b[33miclac\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))\n",
    "                               ])\n",
    "\n",
    "# Loading the training dataset. We need to split it into a training and validation part\n",
    "train_set = CIFAR10(root=DATASET_PATH, train=True, transform=transform, download=True)\n",
    "\n",
    "# Loading the test set\n",
    "test_set = CIFAR10(root=DATASET_PATH, train=False, transform=transform, download=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data_utils.DataLoader(train_set, batch_size=256, shuffle=True,  drop_last=True,  num_workers=4, pin_memory=True)\n",
    "test_loader  = data_utils.DataLoader(test_set,  batch_size=512, shuffle=False, drop_last=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Swish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "    \n",
    "class ConfigurableCNNModel(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_channels=3, \n",
    "                 hidden_features=64, \n",
    "                 depth=4, \n",
    "                 out_dim=1, \n",
    "                 activation_fn=Swish, \n",
    "                 pool_type='max', \n",
    "                 pool_every=2, \n",
    "                 kernel_size=3,\n",
    "                 stride=1,  # Adjusting stride for maintaining dimensions\n",
    "                 padding=1, # Adjusting padding for maintaining dimensions\n",
    "                 final_pooling=True,\n",
    "                 input_size=(32, 32),  # Input size of the image\n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        # List to hold the layers\n",
    "        cnn_layers = []\n",
    "        in_channels = input_channels\n",
    "        \n",
    "        # Activation function\n",
    "        self.activation_fn = activation_fn()\n",
    "        \n",
    "        # Pooling layer setup\n",
    "        if pool_type == 'max':\n",
    "            pooling_layer = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        elif pool_type == 'avg':\n",
    "            pooling_layer = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        else:\n",
    "            raise ValueError(\"pool_type must be either 'max' or 'avg'\")\n",
    "        \n",
    "        # Track the current spatial dimensions of the feature map\n",
    "        current_height, current_width = input_size\n",
    "        \n",
    "        # Generate CNN layers based on the specified depth\n",
    "        for i in range(depth):\n",
    "            out_channels = hidden_features * (2 ** i)\n",
    "            cnn_layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding))\n",
    "            cnn_layers.append(self.activation_fn)\n",
    "            in_channels = out_channels  # Update in_channels for the next layer\n",
    "            \n",
    "            # Calculate the output size after this convolution\n",
    "            current_height = (current_height - kernel_size + 2 * padding) // stride + 1\n",
    "            current_width = (current_width - kernel_size + 2 * padding) // stride + 1\n",
    "            \n",
    "            # Apply pooling if needed\n",
    "            if (i + 1) % pool_every == 0:\n",
    "                cnn_layers.append(pooling_layer)\n",
    "                current_height //= 2\n",
    "                current_width //= 2\n",
    "        \n",
    "        # Optionally add a final pooling layer to reduce the spatial dimension further\n",
    "        if final_pooling:\n",
    "            cnn_layers.append(pooling_layer)\n",
    "            current_height //= 2\n",
    "            current_width //= 2\n",
    "        \n",
    "        # Flatten the output and add fully connected layers\n",
    "        cnn_layers.append(nn.Flatten())\n",
    "        \n",
    "        # Determine the flattened size after convolution and pooling\n",
    "        flattened_size = in_channels * current_height * current_width\n",
    "        \n",
    "        cnn_layers.append(nn.Linear(flattened_size, in_channels))\n",
    "        cnn_layers.append(self.activation_fn)\n",
    "        cnn_layers.append(nn.Linear(in_channels, out_dim))\n",
    "        \n",
    "        # Wrap the list of layers into an nn.Sequential module\n",
    "        self.cnn_layers = nn.Sequential(*cnn_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x).squeeze(dim=-1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18\n",
    "\n",
    "class ConfigurableResNetModel(nn.Module):\n",
    "    def __init__(self, input_channels=3, hidden_features=512, out_dim=1, **kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Load a pre-trained ResNet-18 model and modify it for CIFAR-10 input size\n",
    "        self.resnet = resnet18(weights=torchvision.models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "        \n",
    "        # Modify the input layer if the number of channels is different from 3\n",
    "        if input_channels != 3:\n",
    "            self.resnet.conv1 = nn.Conv2d(input_channels, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        \n",
    "        # Adjust the maxpooling and fully connected layers\n",
    "        self.resnet.maxpool = nn.Identity()  # Remove maxpooling for CIFAR-10's small input size\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Linear(512, hidden_features),\n",
    "            Swish(),\n",
    "            nn.Linear(hidden_features, out_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        return x.squeeze(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampler:\n",
    "    def __init__(self, model, img_shape, sample_size, max_len=8192):\n",
    "        self.model = model\n",
    "        self.img_shape = img_shape\n",
    "        self.sample_size = sample_size\n",
    "        self.max_len = max_len\n",
    "        self.examples = [(torch.rand((1,)+img_shape)*2-1) for _ in range(self.sample_size)]\n",
    "\n",
    "    def sample_new_exmps(self, steps=60, step_size=10):\n",
    "        \"\"\"\n",
    "        Function for getting a new batch of \"fake\" images.\n",
    "        Inputs:\n",
    "            steps - Number of iterations in the MCMC algorithm\n",
    "            step_size - Learning rate nu in the algorithm above\n",
    "        \"\"\"\n",
    "        # Choose 95% of the batch from the buffer, 5% generate from scratch\n",
    "        n_new = np.random.binomial(self.sample_size, 0.05)\n",
    "        rand_imgs = torch.rand((n_new,) + self.img_shape) * 2 - 1\n",
    "        old_imgs = torch.cat(random.choices(self.examples, k=self.sample_size-n_new), dim=0)\n",
    "        inp_imgs = torch.cat([rand_imgs, old_imgs], dim=0).detach().to(device)\n",
    "\n",
    "        # Perform MCMC sampling\n",
    "        inp_imgs = Sampler.generate_samples(self.model, inp_imgs, steps=steps, step_size=step_size)\n",
    "\n",
    "        # Add new images to the buffer and remove old ones if needed\n",
    "        self.examples = list(inp_imgs.to(torch.device(\"cpu\")).chunk(self.sample_size, dim=0)) + self.examples\n",
    "        self.examples = self.examples[:self.max_len]\n",
    "        return inp_imgs\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_samples(model, inp_imgs, steps=60, step_size=10, return_img_per_step=False):\n",
    "        is_training = model.training\n",
    "        model.eval()\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad_(False)\n",
    "\n",
    "        noise = torch.randn_like(inp_imgs)\n",
    "        imgs_per_step = []\n",
    "        inp_imgs.requires_grad_(True)\n",
    "\n",
    "        # Enable gradient calculation if not already the case\n",
    "        had_gradients_enabled = torch.is_grad_enabled()\n",
    "        torch.set_grad_enabled(True)\n",
    "\n",
    "        for _ in range(steps):\n",
    "            noise.normal_(0, 0.005)\n",
    "            inp_imgs.data.add_(noise.data)\n",
    "            inp_imgs.data.clamp_(min=-1.0, max=1.0)\n",
    "\n",
    "            # Part 2: calculate gradients for the current input.\n",
    "            out_imgs = -model(inp_imgs)\n",
    "            out_imgs.sum().backward()\n",
    "            inp_imgs.grad.data.clamp_(-0.03, 0.03) # For stabilizing and preventing too high gradients\n",
    "\n",
    "            # Apply gradients to our current samples\n",
    "            inp_imgs.data.add_(-step_size * inp_imgs.grad.data)\n",
    "            inp_imgs.grad.detach_()\n",
    "            inp_imgs.grad.zero_()\n",
    "            inp_imgs.data.clamp_(min=-1.0, max=1.0)\n",
    "\n",
    "            if return_img_per_step:\n",
    "                imgs_per_step.append(inp_imgs.clone().detach())\n",
    "\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = True\n",
    "        model.train(is_training)\n",
    "        torch.set_grad_enabled(had_gradients_enabled)\n",
    "\n",
    "        if return_img_per_step:\n",
    "            return torch.stack(imgs_per_step, dim=0)\n",
    "        else:\n",
    "            return inp_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepEnergyModel(pl.LightningModule):\n",
    "    def __init__(self, model_class, img_shape, batch_size, alpha=0.1, lr=1e-4, beta1=0.0, **model_args):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.cnn = model_class(**model_args)\n",
    "        self.sampler = Sampler(self.cnn, img_shape=img_shape, sample_size=batch_size)\n",
    "        self.example_input_array = torch.zeros(1, *img_shape)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.cnn(x)\n",
    "        return z\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Energy models can have issues with momentum as the loss surfaces changes with its parameters.\n",
    "        # Hence, we set it to 0 by default.\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.hparams.lr, betas=(self.hparams.beta1, 0.999))\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.97) # Exponential decay over epochs\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # We add minimal noise to the original images to prevent the model from focusing on purely \"clean\" inputs\n",
    "        real_imgs, _ = batch\n",
    "        small_noise = torch.randn_like(real_imgs) * 0.005\n",
    "        real_imgs.add_(small_noise).clamp_(min=-1.0, max=1.0)\n",
    "\n",
    "        # Obtain samples\n",
    "        fake_imgs = self.sampler.sample_new_exmps(steps=60, step_size=10)\n",
    "\n",
    "        # Predict energy score for all images\n",
    "        inp_imgs = torch.cat([real_imgs, fake_imgs], dim=0)\n",
    "        real_out, fake_out = self.cnn(inp_imgs).chunk(2, dim=0)\n",
    "\n",
    "        # Calculate losses\n",
    "        reg_loss = self.hparams.alpha * (real_out ** 2 + fake_out ** 2).mean()\n",
    "        cdiv_loss = fake_out.mean() - real_out.mean()\n",
    "        loss = reg_loss + cdiv_loss\n",
    "\n",
    "        # Logging\n",
    "        self.log('loss', loss)\n",
    "        self.log('loss_regularization', reg_loss)\n",
    "        self.log('loss_contrastive_divergence', cdiv_loss)\n",
    "        self.log('metrics_avg_real', real_out.mean())\n",
    "        self.log('metrics_avg_fake', fake_out.mean())\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # For validating, we calculate the contrastive divergence between purely random images and unseen examples\n",
    "        # Note that the validation/test step of energy-based models depends on what we are interested in the model\n",
    "        real_imgs, _ = batch\n",
    "        fake_imgs = torch.rand_like(real_imgs) * 2 - 1\n",
    "\n",
    "        inp_imgs = torch.cat([real_imgs, fake_imgs], dim=0)\n",
    "        real_out, fake_out = self.cnn(inp_imgs).chunk(2, dim=0)\n",
    "\n",
    "        cdiv = fake_out.mean() - real_out.mean()\n",
    "        self.log('val_contrastive_divergence', cdiv)\n",
    "        self.log('val_fake_out', fake_out.mean())\n",
    "        self.log('val_real_out', real_out.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateCallback(pl.Callback):\n",
    "    def __init__(self, batch_size=8, vis_steps=8, num_steps=256, every_n_epochs=5):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size         # Number of images to generate\n",
    "        self.vis_steps = vis_steps           # Number of steps within generation to visualize\n",
    "        self.num_steps = num_steps           # Number of steps to take during generation\n",
    "        self.every_n_epochs = every_n_epochs # Only save those images every N epochs (otherwise tensorboard gets quite large)\n",
    "\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        # Skip for all other epochs\n",
    "        if trainer.current_epoch % self.every_n_epochs == 0:\n",
    "            # Generate images\n",
    "            imgs_per_step = self.generate_imgs(pl_module)\n",
    "            # Plot and add to tensorboard\n",
    "            for i in range(imgs_per_step.shape[1]):\n",
    "                step_size = self.num_steps // self.vis_steps\n",
    "                imgs_to_plot = imgs_per_step[step_size-1::step_size,i]\n",
    "                grid = torchvision.utils.make_grid(imgs_to_plot, nrow=imgs_to_plot.shape[0], normalize=True, value_range=(-1,1))\n",
    "                trainer.logger.log_image(f\"generation_{i}\", [grid], step=trainer.current_epoch)\n",
    "\n",
    "    def generate_imgs(self, pl_module):\n",
    "        pl_module.eval()\n",
    "        start_imgs = torch.rand((self.batch_size,) + pl_module.hparams[\"img_shape\"]).to(pl_module.device)\n",
    "        start_imgs = start_imgs * 2 - 1\n",
    "        torch.set_grad_enabled(True)  # Tracking gradients for sampling necessary\n",
    "        imgs_per_step = Sampler.generate_samples(pl_module.cnn, start_imgs, steps=self.num_steps, step_size=10, return_img_per_step=True)\n",
    "        torch.set_grad_enabled(False)\n",
    "        pl_module.train()\n",
    "        return imgs_per_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SamplerCallback(pl.Callback):\n",
    "    def __init__(self, num_imgs=32, every_n_epochs=5):\n",
    "        super().__init__()\n",
    "        self.num_imgs = num_imgs             # Number of images to plot\n",
    "        self.every_n_epochs = every_n_epochs # Only save those images every N epochs (otherwise tensorboard gets quite large)\n",
    "\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        if trainer.current_epoch % self.every_n_epochs == 0:\n",
    "            exmp_imgs = torch.cat(random.choices(pl_module.sampler.examples, k=self.num_imgs), dim=0)\n",
    "            grid = torchvision.utils.make_grid(exmp_imgs, nrow=4, normalize=True, value_range=(-1,1))\n",
    "            trainer.logger.log_image(\"sampler\", [grid], step=trainer.current_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutlierCallback(pl.Callback):\n",
    "    def __init__(self, batch_size=1024):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def on_epoch_end(self, trainer, pl_module):\n",
    "        with torch.no_grad():\n",
    "            pl_module.eval()\n",
    "            rand_imgs = torch.rand((self.batch_size,) + pl_module.hparams[\"img_shape\"]).to(pl_module.device)\n",
    "            rand_imgs = rand_imgs * 2 - 1.0\n",
    "            rand_out = pl_module.cnn(rand_imgs).mean()\n",
    "            pl_module.train()\n",
    "\n",
    "        trainer.logger.experiment.add_scalar(\"rand_out\", rand_out, global_step=trainer.current_epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(**kwargs):\n",
    "    wandb_logger = WandbLogger(project='ebm-cifar10', log_model=\"all\")\n",
    "    # Create a PyTorch Lightning trainer with the generation callback\n",
    "    trainer = pl.Trainer(default_root_dir=os.path.join(CHECKPOINT_PATH, \"CIFAR10\"),\n",
    "                         accelerator=\"gpu\" if str(device).startswith(\"cuda\") else \"cpu\",\n",
    "                         devices=1,\n",
    "                         max_epochs=120,\n",
    "                         gradient_clip_val=0.1,\n",
    "                         logger=wandb_logger,\n",
    "                         callbacks=[ModelCheckpoint(save_weights_only=True, mode=\"min\", monitor='val_contrastive_divergence'),\n",
    "                                    GenerateCallback(every_n_epochs=1),\n",
    "                                    SamplerCallback(every_n_epochs=1),\n",
    "                                    OutlierCallback(),\n",
    "                                    LearningRateMonitor(\"epoch\")\n",
    "                                   ])\n",
    "    # Check whether pretrained model exists. If yes, load it and skip training\n",
    "    # pretrained_filename = os.path.join(CHECKPOINT_PATH, \"MNIST.ckpt\")\n",
    "    # if os.path.isfile(pretrained_filename):\n",
    "    #     print(\"Found pretrained model, loading...\")\n",
    "    #     model = DeepEnergyModel.load_from_checkpoint(pretrained_filename)\n",
    "    # else:\n",
    "    pl.seed_everything(55)\n",
    "    model = DeepEnergyModel(**kwargs)\n",
    "    # compiled_model = torch.compile(model)\n",
    "    trainer.fit(model, train_loader, test_loader)\n",
    "    # model = DeepEnergyModel.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n",
    "    # No testing as we are more interested in other properties\n",
    "    wandb.finish()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Seed set to 55\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20240819_103724-v00l23sb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/iclac/ebm-cifar10/runs/v00l23sb' target=\"_blank\">pretty-water-19</a></strong> to <a href='https://wandb.ai/iclac/ebm-cifar10' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/iclac/ebm-cifar10' target=\"_blank\">https://wandb.ai/iclac/ebm-cifar10</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/iclac/ebm-cifar10/runs/v00l23sb' target=\"_blank\">https://wandb.ai/iclac/ebm-cifar10/runs/v00l23sb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]\n",
      "\n",
      "  | Name | Type                 | Params | Mode  | In sizes       | Out sizes\n",
      "-----------------------------------------------------------------------------------\n",
      "0 | cnn  | ConfigurableCNNModel | 4.6 M  | train | [1, 3, 32, 32] | [1]      \n",
      "-----------------------------------------------------------------------------------\n",
      "4.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.6 M     Total params\n",
      "18.263    Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16:  56%|█████▌    | 109/195 [02:41<02:07,  0.67it/s, v_num=23sb]    "
     ]
    }
   ],
   "source": [
    "model = train_model(\n",
    "    model_class=ConfigurableCNNModel,\n",
    "    img_shape=(3,32,32),\n",
    "    batch_size=train_loader.batch_size,\n",
    "    lr=5e-4,\n",
    "    beta1=0.0,\n",
    "    hidden_features=64,\n",
    "    depth=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConfigurableCNNModel(\n",
       "  (activation_fn): Swish()\n",
       "  (cnn_layers): Sequential(\n",
       "    (0): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Swish()\n",
       "    (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): Swish()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): Swish()\n",
       "    (7): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): Swish()\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(1024, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): Swish()\n",
       "    (12): Conv2d(2048, 4096, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): Swish()\n",
       "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (16): Flatten(start_dim=1, end_dim=-1)\n",
       "    (17): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "    (18): Swish()\n",
       "    (19): Linear(in_features=4096, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr-Adam</td><td>▁</td></tr><tr><td>trainer/global_step</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr-Adam</td><td>0.001</td></tr><tr><td>trainer/global_step</td><td>0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">drawn-butterfly-14</strong> at: <a href='https://wandb.ai/iclac/ebm-cifar10/runs/dgirltso' target=\"_blank\">https://wandb.ai/iclac/ebm-cifar10/runs/dgirltso</a><br/> View project at: <a href='https://wandb.ai/iclac/ebm-cifar10' target=\"_blank\">https://wandb.ai/iclac/ebm-cifar10</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240816_140255-dgirltso/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.12 (test1)",
   "language": "python",
   "name": "python312_test1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
